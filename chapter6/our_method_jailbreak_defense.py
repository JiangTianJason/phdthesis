###Section 6.2.2（4），Table 6.9

# ##jailbreak-classifier，See：https://hf-mirror.com/datasets/jackhhao/jailbreak-classification####
# from transformers import pipeline
# import pandas as pd
# from tqdm import tqdm
# from transformers import (
#     BertForSequenceClassification,
#     BertTokenizerFast
# )
# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
#
# test = pd.read_csv(fr"./jailbreak_llms-main/data/balanced_jailbreak_dataset_test_balanced.csv",sep=",").values
#
# path = r"jailbreak-classifier"      ###the model is saved locally
# tokenizer = BertTokenizerFast.from_pretrained(path)
# model = BertForSequenceClassification.from_pretrained(path) # load our fine-tuned model locally
#
# # initialize an inference pipeline with our local fine-tuned model
# classifier = pipeline(task="text-classification", model=model, tokenizer=tokenizer,truncation=True)
#
# prediction = []
# label = []
# for i in tqdm(test):
#     pred = 0 if classifier(i[0])[0]["label"] == "benign" else 1       ###（Equation 6.14）
#     prediction.append(pred)
#     lab = 0 if i[1] == "benign" else 1
#     label.append(lab)
#
# print(classification_report(label,prediction,digits=5))



###Detecting semantic similarity and vector store with LangKit，References：https://whylabs.ai/blog/posts/navigating-threats-detecting-llm-prompt-injections-and-jailbreaks###
###pip install sentence-transformers==2.2.2###
# from langkit import injections, extract
# from sklearn.metrics import classification_report
# import pandas as pd
# from tqdm import tqdm
####------the transformed vector generated by all-MiniLM-L6-v2 from balanced_jailbreak_dataset_train_balanced.csv, the maximum score as the final score, threshold = 0.5
# from sentence_transformers import SentenceTransformer
# import numpy as np
#
# model = SentenceTransformer(r"all-MiniLM-L6-v2")      ###the model is saved locally
#
# sentences = pd.read_csv(fr"./jailbreak_llms-main/data/balanced_jailbreak_dataset_train_balanced.csv",sep=",").values
# sentences = [i[0] for i  in sentences if i[1] == "jailbreak"]
#
# # Generate embeddings
# embeddings = model.encode(sentences)
# target_norms = embeddings / np.linalg.norm(
#     embeddings, axis=1, keepdims=True
# )
# np.save(r"./all-MiniLM-L6-v2_on_train_harm.npy",embeddings)
####------
#
# schema = injections.init()
# test = pd.read_csv(fr"./jailbreak_llms-main/data/balanced_jailbreak_dataset_test_balanced.csv",sep=",").values
#
# prediction = []
# label = []
# for i in tqdm(test):
#     prompt = i[0]
#     result = extract({"prompt": prompt}, schema=schema)
#     pred = 0 if result['prompt.injection'] < 0.5 else 1       ###（Equation 6.15）
#     prediction.append(pred)
#     lab = 0 if i[1] == "benign" else 1
#     label.append(lab)
#
# print(classification_report(label,prediction,digits=5))



####Our method: SVC####
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
np.random.seed(42)
from sklearn.metrics import classification_report
from sklearn.svm import SVC

def load_embedding(dataset_type):
    loaded_embeddings = np.load(fr"./embed_result/Jailbreak_embed_result/balanced_jailbreak_dataset_{dataset_type}_embedding_batch.npy")
    labels = pd.read_csv(fr"./jailbreak_llms-main/data/balanced_jailbreak_dataset_{dataset_type}_balanced.csv",sep=",")
    labels = [0 if i == "benign" else 1 for i in labels.values[:,1]]
    return loaded_embeddings,np.array(labels)

train_embedding,train_label = load_embedding("train")
test_embedding,test_label = load_embedding("test")

outlier_detection_model = SVC(random_state=42)
outlier_detection_model.fit(train_embedding,train_label)

predictions = outlier_detection_model.predict(test_embedding)

print(classification_report(test_label,predictions,digits=5))



# ####protectai/deberta-v3-base-prompt-injection-v2, References: https://hf-mirror.com/protectai/deberta-v3-base-prompt-injection-v2
# from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
# import torch
# import pandas as pd
# from tqdm import tqdm
#
# tokenizer = AutoTokenizer.from_pretrained(r"deberta-v3-base-prompt-injection-v2")   ###the model is saved locally
# model = AutoModelForSequenceClassification.from_pretrained(r"deberta-v3-base-prompt-injection-v2")
#
# classifier = pipeline(
#   "text-classification",
#   model=model,
#   tokenizer=tokenizer,
#   truncation=True,
#   max_length=512,
#   device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
# )
#
# from sklearn.metrics import classification_report
#
# test = pd.read_csv(fr"./jailbreak_llms-main/data/balanced_jailbreak_dataset_test_balanced.csv",sep=",").values
#
# prediction = []
# label = []
# for i in tqdm(test):
#     pred = 0 if classifier(i[0])[0]["label"] == "SAFE" else 1       ###（Equation 6.14），“SAFE” means “benign”
#     prediction.append(pred)
#     lab = 0 if i[1] == "benign" else 1
#     label.append(lab)
#
# print(classification_report(label,prediction,digits=5))



# ##Prompt-Guard-86M, References: https://hf-mirror.com/meta-llama/Prompt-Guard-86M
# from transformers import pipeline
# import pandas as pd
# from tqdm import tqdm
# from transformers import pipeline
# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
#
# test = pd.read_csv(fr"./jailbreak_llms-main/data/balanced_jailbreak_dataset_test_balanced.csv",sep=",").values
#
# model = r'/root/autodl-tmp/Llama-Prompt-Guard-2-86M'     ###the model is saved locally
# # initialize an inference pipeline with our local fine-tuned model
# classifier = pipeline(task="text-classification", model=model,device = "cuda:0")
#
# prediction = []
# label = []
# for i in tqdm(test):
#     print(classifier(i[0]))
#     pred = 0 if classifier(i[0])[0]["label"] == "BENIGN" else 1          ###（Equation 6.14）
#     prediction.append(pred)
#     lab = 0 if i[1] == "benign" else 1
#     label.append(lab)
#
# print(classification_report(label,prediction,digits=5))